{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closure_graph(synset,fn):\n",
    "    seen = set()\n",
    "    node = set()\n",
    "    edge = list()\n",
    "    synsets = []\n",
    "    def recurse(s):\n",
    "        if not s in seen:\n",
    "            seen.add(s)\n",
    "            print(s.lemma_names('eng')[0])\n",
    "            for i in range(len(s.lemma_names('eng'))):\n",
    "                node.add(s.lemma_names('eng')[i])\n",
    "            #node.add(s.lemma_names('eng')[0])\n",
    "            synsets.append(s.lemma_names('eng'))\n",
    "            for s1 in fn(s):\n",
    "                node.add(s1.lemma_names('eng')[0])\n",
    "                edge.append({\"source\":s.lemma_names('eng')[0],\"target\":s1.lemma_names('eng')[0], \"type\":\"hyper\"})\n",
    "                recurse(s1)\n",
    "    recurse(synset)\n",
    "    return (list(node),edge,synsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n",
      "canine\n",
      "carnivore\n",
      "placental\n",
      "mammal\n",
      "vertebrate\n",
      "chordate\n",
      "animal\n",
      "organism\n",
      "living_thing\n",
      "whole\n",
      "object\n",
      "physical_entity\n",
      "entity\n",
      "domestic_animal\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "dog = wn.synset('dog.n.01')\n",
    "graph = closure_graph(dog,lambda s: s.hypernyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 1, 'name': 'organism'}, {'id': 2, 'name': 'animate_thing'}, {'id': 3, 'name': 'domestic_dog'}, {'id': 4, 'name': 'mammalian'}, {'id': 5, 'name': 'eutherian_mammal'}, {'id': 6, 'name': 'chordate'}, {'id': 7, 'name': 'being'}, {'id': 8, 'name': 'mammal'}, {'id': 9, 'name': 'living_thing'}, {'id': 10, 'name': 'canine'}, {'id': 11, 'name': 'craniate'}, {'id': 12, 'name': 'object'}, {'id': 13, 'name': 'animal'}, {'id': 14, 'name': 'unit'}, {'id': 15, 'name': 'eutherian'}, {'id': 16, 'name': 'animate_being'}, {'id': 17, 'name': 'brute'}, {'id': 18, 'name': 'creature'}, {'id': 19, 'name': 'physical_object'}, {'id': 20, 'name': 'dog'}, {'id': 21, 'name': 'beast'}, {'id': 22, 'name': 'placental'}, {'id': 23, 'name': 'canid'}, {'id': 24, 'name': 'Canis_familiaris'}, {'id': 25, 'name': 'placental_mammal'}, {'id': 26, 'name': 'fauna'}, {'id': 27, 'name': 'domestic_animal'}, {'id': 28, 'name': 'entity'}, {'id': 29, 'name': 'domesticated_animal'}, {'id': 30, 'name': 'carnivore'}, {'id': 31, 'name': 'physical_entity'}, {'id': 32, 'name': 'whole'}, {'id': 33, 'name': 'vertebrate'}]\n"
     ]
    }
   ],
   "source": [
    "vocabulary = []\n",
    "for token in graph[0]:\n",
    "    if token not in vocabulary:\n",
    "        vocabulary.append(token)\n",
    "json_1 = []\n",
    "for i in range(len(vocabulary)):\n",
    "    json_1.append({\"id\":i+1, \"name\": vocabulary[i]})\n",
    "\n",
    "vocabulary_size = len(vocabulary)\n",
    "print(json_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_2 = graph[1] #will be used for hypernyms \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(graph[2])):\n",
    "    for j in range(len(graph[2][i])):\n",
    "        json_2.append({\"source\":graph[2][i][0], \"target\": graph[2][i][j], \"type\":\"sin\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(json_1)):\n",
    "    for i in range(len(graph[1])):    \n",
    "        if (json_1[j]['name'] ==  json_2[i]['source']):\n",
    "            json_2[i]['source'] = json_1[j]['id']\n",
    "        if (json_1[j]['name'] ==  json_2[i]['target']):\n",
    "            json_2[i]['target'] = json_1[j]['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"wordnet2.json\",\"w\") as fh:\n",
    "    json.dump({\"nodes\":json_1,\"links\":json_2},fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
